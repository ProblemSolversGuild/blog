{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"fastai's Text DLs Exploration\"\n",
    "> \"Exploring different methods to create the dls object in fastai\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Kevin Bird\n",
    "- categories: [fastai, technical, exploration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is an exploration into how to convert data into dls objects that can be used by fastai's learner.  I was having issues creating a dls object that had the ability to `show_batch` and met my arbitrarily custom needs.  So I set out to figure out how to create dls that worked well for my needs.  \n",
    "\n",
    "This blog post uses the Human Numbers dataset which is a dataset that counts sequentially from 1 to 9999 but in english text rather than numerical form.  This is an interesting problem because there is quite a bit of repetition, but also new tokens and patterns being introduced regularly that a model will need to figure out.  \n",
    "\n",
    "My goal was to create a dls that would have X=1,2,3 and y=4.  Over the course of this blog post, I will show ~4 ways to create dls that enable show_batch to work as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:39:33.472183Z",
     "start_time": "2021-05-15T05:39:29.635134Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:43:24.105088Z",
     "start_time": "2021-05-15T05:43:24.101411Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:43:55.506024Z",
     "start_time": "2021-05-15T05:43:55.500418Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastai, fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:44:16.847986Z",
     "start_time": "2021-05-15T05:44:16.838184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.1', '1.3.20')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__,fastcore.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:44:07.938459Z",
     "start_time": "2021-05-15T05:44:07.927351Z"
    }
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.HUMAN_NUMBERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I create a tokenizer, combine all of the text into a single string, and tokenize each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.649533Z",
     "start_time": "2021-05-14T20:14:39.488065Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordTokenizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.654206Z",
     "start_time": "2021-05-14T20:14:39.650566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) ['xxbos','one','two','three']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('one two three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.664175Z",
     "start_time": "2021-05-14T20:14:39.655063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) ['xxbos','one',',','two']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('one, two')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:09:04.018993Z",
     "start_time": "2021-05-14T20:09:04.016369Z"
    }
   },
   "source": [
    "Reading the train and validation files:  \n",
    "* train - [1-8000]\n",
    "* valid = [8001-9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.673816Z",
     "start_time": "2021-05-14T20:14:39.664967Z"
    }
   },
   "outputs": [],
   "source": [
    "train_txt = ', '.join(o.strip() for o in (path/'train.txt').readlines())\n",
    "valid_txt = ', '.join(o.strip() for o in (path/'valid.txt').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I will create my own validation set.  It will split close to the same as this, but by creating my own split, I don't have to do anything special when creating chunks around the train->validation split point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.683394Z",
     "start_time": "2021-05-14T20:14:39.678260Z"
    }
   },
   "outputs": [],
   "source": [
    "all_text = train_txt+valid_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.885952Z",
     "start_time": "2021-05-14T20:14:39.685073Z"
    }
   },
   "outputs": [],
   "source": [
    "all_text_tok = tokenizer(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.889085Z",
     "start_time": "2021-05-14T20:14:39.887034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#63094) ['xxbos','one',',','two',',','three',',','four',',','five'...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I take the tokenized text, count how many times each tokenizer occurs and create a vocab with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.901008Z",
     "start_time": "2021-05-14T20:14:39.889799Z"
    }
   },
   "outputs": [],
   "source": [
    "count=Counter(all_text_tok)\n",
    "vocab = make_vocab(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.909618Z",
     "start_time": "2021-05-14T20:14:39.901792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({',': 9996, 'hundred': 9000, 'thousand': 8999, 'one': 2900, 'two': 2900, 'three': 2900, 'four': 2900, 'five': 2900, 'six': 2900, 'seven': 2900, 'nine': 2899, 'eight': 2898, 'twenty': 1000, 'thirty': 1000, 'forty': 1000, 'fifty': 1000, 'sixty': 1000, 'seventy': 1000, 'eighty': 1000, 'ninety': 1000, 'ten': 100, 'eleven': 100, 'twelve': 100, 'thirteen': 100, 'fourteen': 100, 'fifteen': 100, 'sixteen': 100, 'seventeen': 100, 'eighteen': 100, 'nineteen': 100, 'xxbos': 1, 'nineeight': 1})\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.917544Z",
     "start_time": "2021-05-14T20:14:39.910361Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', ',', 'hundred', 'thousand', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'nine', 'eight', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.928109Z",
     "start_time": "2021-05-14T20:14:39.918366Z"
    }
   },
   "outputs": [],
   "source": [
    "all_text_tok_chunked = list(chunked(all_text_tok, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.935925Z",
     "start_time": "2021-05-14T20:14:39.929114Z"
    }
   },
   "outputs": [],
   "source": [
    "#drop last non-full row\n",
    "all_text_tok_chunked = all_text_tok_chunked[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I create something that will get_x and get_y from  the chunked data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.943842Z",
     "start_time": "2021-05-14T20:14:39.936742Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_x(o):\n",
    "    return o[:10]\n",
    "\n",
    "def get_y(o):\n",
    "    return [o[10]] if len(o) == 11 else ['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.952379Z",
     "start_time": "2021-05-14T20:14:39.944704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxbos', 'one', ',', 'two', ',', 'three', ',', 'four', ',', 'five'] -> [',']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{get_x(all_text_tok_chunked[0])} -> {get_y(all_text_tok_chunked[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.960130Z",
     "start_time": "2021-05-14T20:14:39.953221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nine', 'thousand', 'nine', 'hundred', 'ninety', 'seven', ',', 'nine', 'thousand', 'nine'] -> ['hundred']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{get_x(all_text_tok_chunked[-1])} -> {get_y(all_text_tok_chunked[-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TitledStringDecoder is a transform that only decodes and what it enables is the show_batch and show_results function to actually work properly.  Without this, I had troubles getting those functions to work because TensorText doesn't have a proper show function or a truncate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.967829Z",
     "start_time": "2021-05-14T20:14:39.961004Z"
    }
   },
   "outputs": [],
   "source": [
    "class TitledStringDecoder(Transform):\n",
    "    def decodes(self, o):\n",
    "        return TitledStr(' '.join(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All TitledStringDecoder really does is takes an array of text ('one', 'two') and converts it into a space-concatenated string instead of type Titled str which knows how to display itself in a nice way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.976425Z",
     "start_time": "2021-05-14T20:14:39.968677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one two'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitledStr(' '.join(['one', 'two']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.983446Z",
     "start_time": "2021-05-14T20:14:39.977263Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_ts = TitledStr(' '.join(all_text_tok[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.991594Z",
     "start_time": "2021-05-14T20:14:39.984407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos one , two , three , four , five'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:39.999886Z",
     "start_time": "2021-05-14T20:14:39.992424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos one ,'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ts.truncate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create the splits based off the chunks.  Putting 80% of the chunks into the training set and the last 20% in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:40.007291Z",
     "start_time": "2021-05-14T20:14:40.001606Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = [L(range(int(len(all_text_tok_chunked)*0.8))), L(range(int(len(all_text_tok_chunked)*0.8),len(all_text_tok_chunked)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:40.015206Z",
     "start_time": "2021-05-14T20:14:40.008295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#4588) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#1147) [4588,4589,4590,4591,4592,4593,4594,4595,4596,4597...]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the transforms work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:40.024634Z",
     "start_time": "2021-05-14T20:14:40.016052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([ 2, 12,  9, 13,  9, 14,  9, 15,  9, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Numericalize(vocab)(TitledStringDecoder()(get_x(all_text_tok_chunked[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And confirm that they will work as a pipeline as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:40.036605Z",
     "start_time": "2021-05-14T20:14:40.025523Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([TitledStringDecoder, Numericalize(vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:14:45.620235Z",
     "start_time": "2021-05-14T20:14:45.608320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([ 2, 12,  9, 13,  9, 14,  9, 15,  9, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_x(pipeline(all_text_tok_chunked[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:30.153079Z",
     "start_time": "2021-05-14T20:16:30.148348Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_x = Pipeline([get_x, TitledStringDecoder, Numericalize(vocab)])\n",
    "pipeline_y = Pipeline([get_y, TitledStringDecoder, Numericalize(vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:31.036450Z",
     "start_time": "2021-05-14T20:16:31.032927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_y(all_text_tok_chunked[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Datasets + Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:49.130576Z",
     "start_time": "2021-05-14T20:16:49.119040Z"
    }
   },
   "outputs": [],
   "source": [
    "dsets = Datasets(all_text_tok_chunked, tfms=[pipeline_x,pipeline_y], splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:49.610728Z",
     "start_time": "2021-05-14T20:16:49.607422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([ 2, 12,  9, 13,  9, 14,  9, 15,  9, 16]), TensorText([9]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:51.644375Z",
     "start_time": "2021-05-14T20:16:51.638557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos one , two , three , four , five\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "dsets.show(dsets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create the dataloaders.  This can be done with either `DataLoaders.from_dsets(...)` or `dsets.dataloaders(...)`. Both methods are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:53.394816Z",
     "start_time": "2021-05-14T20:16:53.390271Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(dsets, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:53.670354Z",
     "start_time": "2021-05-14T20:16:53.593034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos one , two , three , four , five</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>six , seven , eight , nine , ten ,</td>\n",
       "      <td>eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, twelve , thirteen , fourteen , fifteen , sixteen</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seventeen , eighteen , nineteen , twenty , twenty one</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twenty two , twenty three , twenty four , twenty</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, twenty six , twenty seven , twenty eight ,</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nine , thirty , thirty one , thirty two ,</td>\n",
       "      <td>thirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three , thirty four , thirty five , thirty six</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thirty seven , thirty eight , thirty nine , forty</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:58.825631Z",
     "start_time": "2021-05-14T20:16:57.311002Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(bs=16, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:16:58.845996Z",
     "start_time": "2021-05-14T20:16:58.826632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos one , two , three , four , five</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>six , seven , eight , nine , ten ,</td>\n",
       "      <td>eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, twelve , thirteen , fourteen , fifteen , sixteen</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seventeen , eighteen , nineteen , twenty , twenty one</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twenty two , twenty three , twenty four , twenty</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, twenty six , twenty seven , twenty eight ,</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nine , thirty , thirty one , thirty two ,</td>\n",
       "      <td>thirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three , thirty four , thirty five , thirty six</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thirty seven , thirty eight , thirty nine , forty</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:34:00.549470Z",
     "start_time": "2021-05-12T03:34:00.541850Z"
    }
   },
   "source": [
    "## Using Datasets -> train TfmdDL + valid TfmdDL -> dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get dls is to create TfmdDLs and pass those into DataLoaders.  If you use DataLoader rather than TfmdDL, dls won't have a show_batch method available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:19.756797Z",
     "start_time": "2021-05-14T20:17:19.750489Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = TfmdDL(dsets.train, bs=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:20.498823Z",
     "start_time": "2021-05-14T20:17:20.495324Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_dl = TfmdDL(dsets.valid, bs=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:21.526842Z",
     "start_time": "2021-05-14T20:17:21.520610Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:21.774212Z",
     "start_time": "2021-05-14T20:17:21.748182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos one , two , three , four , five</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>six , seven , eight , nine , ten ,</td>\n",
       "      <td>eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, twelve , thirteen , fourteen , fifteen , sixteen</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seventeen , eighteen , nineteen , twenty , twenty one</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twenty two , twenty three , twenty four , twenty</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, twenty six , twenty seven , twenty eight ,</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nine , thirty , thirty one , thirty two ,</td>\n",
       "      <td>thirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three , thirty four , thirty five , thirty six</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thirty seven , thirty eight , thirty nine , forty</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:24.322085Z",
     "start_time": "2021-05-14T20:17:24.308174Z"
    }
   },
   "outputs": [],
   "source": [
    "X,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataBlock -> datasets -> dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get dataloaders is to use DataBlock.  DataBlock wants to know what type of data will be passed which can be specified to `blocks`.  It also wants a `splitter` and the functions to `get_x` and `get_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:25.801956Z",
     "start_time": "2021-05-14T20:17:25.796645Z"
    }
   },
   "outputs": [],
   "source": [
    "blocks = [TransformBlock(type_tfms=[TitledStringDecoder, Numericalize(vocab)]), # x piece\n",
    "          TransformBlock(type_tfms=[TitledStringDecoder, Numericalize(vocab)])] # y piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:26.009182Z",
     "start_time": "2021-05-14T20:17:26.006091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1147) [4588,4589,4590,4591,4592,4593,4594,4595,4596,4597...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:26.379875Z",
     "start_time": "2021-05-14T20:17:26.367879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#4588) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#1147) [4588,4589,4590,4591,4592,4593,4594,4595,4596,4597...])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IndexSplitter(splits[-1])(all_text_tok_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:26.720054Z",
     "start_time": "2021-05-14T20:17:26.717070Z"
    }
   },
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=blocks,\n",
    "                   splitter=IndexSplitter(splits[-1]),\n",
    "                   get_x=get_x,\n",
    "                   get_y=get_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dblock created, you can create a dset and then from the dset, you can create a dls similar to the one created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:27.399812Z",
     "start_time": "2021-05-14T20:17:27.351179Z"
    }
   },
   "outputs": [],
   "source": [
    "dsets_via_dblock = dblock.datasets(all_text_tok_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:27.719824Z",
     "start_time": "2021-05-14T20:17:27.712937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5735) [(TensorText([ 2, 12,  9, 13,  9, 14,  9, 15,  9, 16]), TensorText([9])),(TensorText([17,  9, 18,  9, 20,  9, 19,  9, 29,  9]), TensorText([30])),(TensorText([ 9, 31,  9, 32,  9, 33,  9, 34,  9, 35]), TensorText([9])),(TensorText([36,  9, 37,  9, 38,  9, 21,  9, 21, 12]), TensorText([9])),(TensorText([21, 13,  9, 21, 14,  9, 21, 15,  9, 21]), TensorText([16])),(TensorText([ 9, 21, 17,  9, 21, 18,  9, 21, 20,  9]), TensorText([21])),(TensorText([19,  9, 22,  9, 22, 12,  9, 22, 13,  9]), TensorText([22])),(TensorText([14,  9, 22, 15,  9, 22, 16,  9, 22, 17]), TensorText([9])),(TensorText([22, 18,  9, 22, 20,  9, 22, 19,  9, 23]), TensorText([9])),(TensorText([23, 12,  9, 23, 13,  9, 23, 14,  9, 23]), TensorText([15]))...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets_via_dblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:27.961370Z",
     "start_time": "2021-05-14T20:17:27.948230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos one , two , three , four , five\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "dsets_via_dblock.show(dsets_via_dblock[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:28.381205Z",
     "start_time": "2021-05-14T20:17:28.349483Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = dsets_via_dblock.dataloaders(bs=16,shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:28.893570Z",
     "start_time": "2021-05-14T20:17:28.857130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos one , two , three , four , five</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>six , seven , eight , nine , ten ,</td>\n",
       "      <td>eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, twelve , thirteen , fourteen , fifteen , sixteen</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seventeen , eighteen , nineteen , twenty , twenty one</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twenty two , twenty three , twenty four , twenty</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, twenty six , twenty seven , twenty eight ,</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nine , thirty , thirty one , thirty two ,</td>\n",
       "      <td>thirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three , thirty four , thirty five , thirty six</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thirty seven , thirty eight , thirty nine , forty</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataBlock -> dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to go directly from dblock to dls with `dblock.dataloaders`.  Behind the scenes this is creating a dataset as well, but it can be a cleaner looking way to handle it if you always go from dblock -> dls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:30.468170Z",
     "start_time": "2021-05-14T20:17:30.448103Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(all_text_tok_chunked, bs=16, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:17:30.869863Z",
     "start_time": "2021-05-14T20:17:30.818000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos one , two , three , four , five</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>six , seven , eight , nine , ten ,</td>\n",
       "      <td>eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, twelve , thirteen , fourteen , fifteen , sixteen</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seventeen , eighteen , nineteen , twenty , twenty one</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twenty two , twenty three , twenty four , twenty</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, twenty six , twenty seven , twenty eight ,</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nine , thirty , thirty one , thirty two ,</td>\n",
       "      <td>thirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three , thirty four , thirty five , thirty six</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thirty seven , thirty eight , thirty nine , forty</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `dls` is an extremely important capability when using fastai because that is what a learn expects to deal with all of the data.  There are many different ways to get a dls object created so this isn't a comprehensive list, but at least shows a few ways to do the task.  In a future blog post, I will be using this dls and exploring transformer models with it.  Hopefully this will help others get their DLs working.  \n",
    "\n",
    "I'd like to give a special thanks to Arto for helping me get things working properly and everybody in the fastai discord channel for dealing with my questions and for creating a great community to learn with every step of the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arampacha.github.io/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html  \n",
    "\n",
    "https://github.com/fastai/fastai/blob/ab154927696338741e59e0ffc4774777c4a9781c/nbs/39_tutorial.transformers.ipynb  \n",
    "https://github.com/fastai/fastai/blob/ab154927696338741e59e0ffc4774777c4a9781c/dev_nbs/course/lesson7-human-numbers.ipynb"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/70b91cfb23ec804d33a08f98103ab2f9"
  },
  "gist": {
   "data": {
    "description": "Research/Transformer/TextPloration.ipynb",
    "public": false
   },
   "id": "70b91cfb23ec804d33a08f98103ab2f9"
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
